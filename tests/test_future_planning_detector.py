"""Unit tests for orchestrator/future_planning_detector.py."""

from __future__ import annotations

import json
import pytest
from unittest.mock import AsyncMock, MagicMock

from orchestrator.future_planning_detector import (
    FuturePlanningDetector,
    FuturePlanningResult,
)


@pytest.fixture
def detector(mock_settings, mock_openai_client):
    return FuturePlanningDetector(
        openai_client=mock_openai_client, settings=mock_settings
    )


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ detect (LLM mocked) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


class TestDetect:
    @pytest.mark.asyncio
    async def test_planning_detected(self, detector, mock_openai_client):
        llm_response = json.dumps(
            {
                "is_future_planning": True,
                "detected_plan": "Ø±ÙØªÙ† Ø¨Ù‡ Ú©ÙˆÙ‡",
                "detected_datetime": "ÙØ±Ø¯Ø§",
                "confidence": 0.92,
                "reason": "Direct planning request",
            }
        )
        mock_resp = MagicMock()
        mock_resp.choices = [MagicMock()]
        mock_resp.choices[0].message.content = llm_response
        mock_resp.usage = MagicMock()
        mock_resp.usage.prompt_tokens = 40
        mock_resp.usage.completion_tokens = 25
        mock_openai_client.chat.completions.create = AsyncMock(return_value=mock_resp)
        detector._client = mock_openai_client

        result = await detector.detect(
            message="ÙØ±Ø¯Ø§ Ø¨Ø±ÛŒÙ… Ú©ÙˆÙ‡ØŸ",
            sender_id="user1",
            recipient_id="owner",
        )

        assert isinstance(result, FuturePlanningResult)
        assert result.is_future_planning is True
        assert result.detected_plan == "Ø±ÙØªÙ† Ø¨Ù‡ Ú©ÙˆÙ‡"
        assert result.confidence >= 0.9

    @pytest.mark.asyncio
    async def test_non_planning(self, detector, mock_openai_client):
        llm_response = json.dumps(
            {
                "is_future_planning": False,
                "detected_plan": "",
                "detected_datetime": None,
                "confidence": 0.05,
                "reason": "Just a greeting",
            }
        )
        mock_resp = MagicMock()
        mock_resp.choices = [MagicMock()]
        mock_resp.choices[0].message.content = llm_response
        mock_resp.usage = MagicMock()
        mock_resp.usage.prompt_tokens = 30
        mock_resp.usage.completion_tokens = 15
        mock_openai_client.chat.completions.create = AsyncMock(return_value=mock_resp)
        detector._client = mock_openai_client

        result = await detector.detect(
            message="Ø³Ù„Ø§Ù…ØŒ Ú†Ø·ÙˆØ±ÛŒØŸ",
            sender_id="user1",
            recipient_id="owner",
        )

        assert result.is_future_planning is False

    @pytest.mark.asyncio
    async def test_llm_error_returns_safe_default(self, detector, mock_openai_client):
        mock_openai_client.chat.completions.create = AsyncMock(
            side_effect=RuntimeError("API error")
        )
        detector._client = mock_openai_client

        result = await detector.detect(
            message="ÙØ±Ø¯Ø§ Ø¨Ø±ÛŒÙ… Ø³ÛŒÙ†Ù…Ø§",
            sender_id="u1",
            recipient_id="owner",
        )

        assert isinstance(result, FuturePlanningResult)
        assert result.is_future_planning is False
        assert result.confidence == 0.0

    @pytest.mark.asyncio
    async def test_detect_with_context(self, detector, mock_openai_client):
        llm_response = json.dumps(
            {
                "is_future_planning": True,
                "detected_plan": "Ù†Ø§Ù‡Ø§Ø± Ø±ÙØªÙ†",
                "detected_datetime": "Ù‡ÙØªÙ‡ Ø¨Ø¹Ø¯",
                "confidence": 0.88,
                "reason": "Planning with context",
            }
        )
        mock_resp = MagicMock()
        mock_resp.choices = [MagicMock()]
        mock_resp.choices[0].message.content = llm_response
        mock_resp.usage = MagicMock()
        mock_resp.usage.prompt_tokens = 60
        mock_resp.usage.completion_tokens = 25
        mock_openai_client.chat.completions.create = AsyncMock(return_value=mock_resp)
        detector._client = mock_openai_client

        result = await detector.detect(
            message="Ù‡ÙØªÙ‡ Ø¨Ø¹Ø¯ ÙˆÙ‚Øª Ø¯Ø§Ø±ÛŒ Ù†Ø§Ù‡Ø§Ø± Ø¨Ø±ÛŒÙ…ØŸ",
            sender_id="u1",
            recipient_id="owner",
            context=["Ø³Ù„Ø§Ù…", "Ø®ÙˆØ¨ÛŒØŸ", "Ù…Ù…Ù†ÙˆÙ†"],
        )

        assert result.is_future_planning is True
        assert result.detected_plan == "Ù†Ø§Ù‡Ø§Ø± Ø±ÙØªÙ†"


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ generate_acknowledgment_response â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


class TestGenerateAcknowledgmentResponse:
    @pytest.mark.asyncio
    async def test_farsi_with_name(self, detector):
        msg = await detector.generate_acknowledgment_response(
            detected_plan="Ø±ÙØªÙ† Ø¨Ù‡ Ú©ÙˆÙ‡",
            detected_datetime="ÙØ±Ø¯Ø§",
            twin_name="Ø³ÛŒØ§Ù…Ú©",
        )
        assert "Ø³ÛŒØ§Ù…Ú©" in msg
        assert "ğŸ‘" in msg

    @pytest.mark.asyncio
    async def test_farsi_without_name(self, detector):
        msg = await detector.generate_acknowledgment_response(
            detected_plan="Ù†Ø§Ù‡Ø§Ø±",
            detected_datetime=None,
            twin_name=None,
        )
        assert "Ø§ÛŒØ´Ø§Ù†" in msg

    @pytest.mark.asyncio
    async def test_english_with_name(self, detector):
        msg = await detector.generate_acknowledgment_response(
            detected_plan="hiking",
            detected_datetime="tomorrow",
            twin_name="John",
            language="en",
        )
        assert "John" in msg
        assert "ğŸ‘" in msg

    @pytest.mark.asyncio
    async def test_english_without_name(self, detector):
        msg = await detector.generate_acknowledgment_response(
            detected_plan="dinner",
            detected_datetime=None,
            twin_name=None,
            language="en",
        )
        assert "Ø§ÛŒØ´Ø§Ù†" in msg or "know" in msg.lower()
