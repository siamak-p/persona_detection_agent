# JoowMe Agent â€” Architecture & How It Works

## Overview

**JoowMe Agent** (internally named **PetaProcTwin**) is an **AI Twin** platform. It creates a digital replica of a real person (the "Creator") that can automatically chat with the creator's contacts, mimicking their tone, personality, and knowledge. The platform learns from the creator's conversations, detects relationships, remembers facts, and handles sensitive topics (financial, future planning) by routing them to the real person.

### Core Concept

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   External Users     â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚      AI Twin (Agent)      â”‚â—€â”€â”€â”€â”€â”€â”€â”‚   Creator (Owner)    â”‚
â”‚   (Friends, Family,  â”‚       â”‚                           â”‚       â”‚                      â”‚
â”‚    Colleagues, etc.) â”‚â—€â”€â”€â”€â”€â”€â”€â”‚  Learns tone, facts,      â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚  Teaches, corrects,  â”‚
â”‚                      â”‚       â”‚  relationship context     â”‚       â”‚  responds to special â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚  topics              â”‚
                                                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

- **External users** chat with the AI Twin thinking they're chatting with the real person.
- **The Creator** trains the twin by chatting with it and responding to special topics (financial, future plans).
- **The AI Twin** learns the creator's personality, tone, facts, and relationships over time.

---

## Technology Stack

| Layer              | Technology                                                |
|--------------------|-----------------------------------------------------------|
| **Web Framework**  | FastAPI (async, Python)                                   |
| **LLM**           | OpenAI API (GPT-4o, GPT-4o-mini, configurable per agent)   |
| **Memory**         | [mem0](https://github.com/mem0ai/mem0) (semantic memory)  |
| **Vector Database**| Qdrant (similarity search)                                |
| **Relational DB**  | PostgreSQL 16 (chat history, feedback, threads)           |
| **Local DB**       | SQLite (mem0 history cache)                               |
| **Embeddings**     | BAAI/bge-m3 (local) or OpenAI embeddings                 |
| **Voice STT**      | OpenAI Whisper API                                        |
| **Voice TTS**      | OpenAI TTS API                                            |
| **DI Container**   | dependency-injector                                       |
| **Observability**  | Phoenix (AI tracing), Prometheus, Grafana                 |
| **Real-time**      | WebSocket (FastAPI native)                                |
| **UI**             | Streamlit (admin/creator dashboard)                       |
| **Containerization**| Docker Compose                                           |

---

## Project Structure

```
joowme-agent/
â”œâ”€â”€ main.py                          # FastAPI app entry point & lifespan
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ settings.py                  # Pydantic settings (env vars)
â”‚   â””â”€â”€ container.py                 # DI container (dependency-injector)
â”œâ”€â”€ api/
â”‚   â””â”€â”€ routers/
â”‚       â”œâ”€â”€ chat.py                  # POST /api/v1/chat
â”‚       â”œâ”€â”€ creator.py               # POST /api/v1/creator
â”‚       â”œâ”€â”€ passive.py               # POST /api/v1/passive
â”‚       â”œâ”€â”€ passive_last_message_id.py # GET /api/v1/passive/last-msgId
â”‚       â”œâ”€â”€ feedback.py              # Feedback, future requests, financial threads
â”‚       â”œâ”€â”€ scheduler.py             # Admin scheduler endpoints
â”‚       â”œâ”€â”€ websocket_notifications.py # WebSocket real-time notifications
â”‚       â””â”€â”€ voice_static.py          # Voice file serving
â”œâ”€â”€ orchestrator/
â”‚   â”œâ”€â”€ orchestrator_agent.py        # Central brain: response composition
â”‚   â”œâ”€â”€ messages.py                  # Pydantic request/response models
â”‚   â”œâ”€â”€ financial_topic_detector.py  # LLM-based financial topic detection
â”‚   â””â”€â”€ future_planning_detector.py  # LLM-based future plan detection
â”œâ”€â”€ service/
â”‚   â”œâ”€â”€ chat_service.py              # Chat business logic + voice I/O
â”‚   â”œâ”€â”€ creator_service.py           # Creator business logic + voice I/O
â”‚   â”œâ”€â”€ passive_service.py           # Passive observation recording
â”‚   â”œâ”€â”€ relationship_feedback_service.py # Relationship questions & feedback
â”‚   â””â”€â”€ voice/
â”‚       â”œâ”€â”€ voice_processor.py       # Voice I/O coordinator
â”‚       â”œâ”€â”€ openai_stt.py            # Speech-to-Text (Whisper)
â”‚       â”œâ”€â”€ openai_tts.py            # Text-to-Speech
â”‚       â””â”€â”€ voice_storage.py         # Voice file storage management
â”œâ”€â”€ memory/
â”‚   â”œâ”€â”€ mem0_adapter.py              # mem0 integration (add/get/search memories)
â”‚   â”œâ”€â”€ attribute_schema.py          # Memory attribute schemas
â”‚   â””â”€â”€ mem_custom_prompt.py         # Custom mem0 extraction prompts
â”œâ”€â”€ listener/
â”‚   â””â”€â”€ listener.py                  # Message logging & summarization trigger
â”œâ”€â”€ guardrail/
â”‚   â””â”€â”€ guardrails_agent.py          # Safety checks, jailbreak detection
â”œâ”€â”€ summarizer/
â”‚   â”œâ”€â”€ summarizer_agent.py          # LLM-based conversation summarization
â”‚   â”œâ”€â”€ core_fact_extractor.py       # Structured fact extraction from text
â”‚   â””â”€â”€ passive_summarizer_agent.py  # Passive observation summarization
â”œâ”€â”€ tone_and_personality_traits_detection/
â”‚   â”œâ”€â”€ tone_detection_agent.py      # LLM-based tone/personality analysis
â”‚   â””â”€â”€ utils.py                     # Tone analysis utilities
â”œâ”€â”€ scheduler/
â”‚   â”œâ”€â”€ tone_scheduler.py            # Periodic tone analysis
â”‚   â”œâ”€â”€ tone_retry_worker.py         # Retry failed tone analyses
â”‚   â”œâ”€â”€ feedback_scheduler.py        # Periodic relationship question generation
â”‚   â”œâ”€â”€ retry_worker.py              # Retry failed summarizations
â”‚   â”œâ”€â”€ passive_scheduler.py         # Passive data scheduling
â”‚   â”œâ”€â”€ passive_summarization_scheduler.py # Passive summarization scheduling
â”‚   â””â”€â”€ passive_summarization_retry_worker.py # Retry passive summarizations (not present as separate file, integrated)
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ postgres.py                  # Async engine/session factories
â”‚   â”œâ”€â”€ postgres_chat_store.py       # Chat event log (PostgreSQL)
â”‚   â”œâ”€â”€ postgres_relationship_cluster_personas.py # Relationship clusters
â”‚   â”œâ”€â”€ postgres_dyadic_overrides.py # Per-pair tone overrides
â”‚   â”œâ”€â”€ postgres_financial_threads.py # Financial thread management
â”‚   â”œâ”€â”€ postgres_future_requests.py  # Future planning request storage
â”‚   â”œâ”€â”€ passive_storage.py           # Passive observation state
â”‚   â”œâ”€â”€ passive_archive_storage.py   # Archived passive observations
â”‚   â”œâ”€â”€ passive_summarization_storage.py # Passive summarization state
â”‚   â”œâ”€â”€ creator_chat_store.py        # Creator chat storage
â”‚   â”œâ”€â”€ tone_retry_storage.py        # Tone retry queue
â”‚   â”œâ”€â”€ qdrant.py                    # Qdrant client config
â”‚   â””â”€â”€ shared_pool.py              # Shared connection pool
â”œâ”€â”€ observability/
â”‚   â”œâ”€â”€ phoenix_setup.py             # OpenTelemetry + Phoenix tracing
â”‚   â”œâ”€â”€ metrics.py                   # Prometheus metrics
â”‚   â”œâ”€â”€ sqlite_metrics.py            # SQLite metrics collector
â”‚   â””â”€â”€ docker/                      # Prometheus/Grafana configs
â”œâ”€â”€ streamlit_ui/
â”‚   â”œâ”€â”€ app.py                       # Streamlit app entry
â”‚   â””â”€â”€ pages.py                     # Dashboard pages
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init_databases.py            # Database initialization
â”‚   â”œâ”€â”€ migrations.py                # Schema migrations
â”‚   â””â”€â”€ load_embedding_model.py      # Embedding model loader
â”œâ”€â”€ docker-compose.yaml              # Qdrant, PostgreSQL, Phoenix, Prometheus, Grafana
â””â”€â”€ requirements.txt                 # Python dependencies
```

---

## How It Works â€” Processing Flow

### 1. Chat Flow (User â†’ AI Twin)

```mermaid
sequenceDiagram
    participant User
    participant API as Chat API
    participant Service as ChatService
    participant Voice as VoiceProcessor
    participant Orch as OrchestratorAgent
    participant Guard as GuardrailsAgent
    participant Mem as Mem0Adapter
    participant LLM as OpenAI LLM
    participant Listener as ListenerAgent
    participant WS as WebSocket

    User->>API: POST /api/v1/chat
    API->>Service: handle_chat()

    alt Voice Input
        Service->>Voice: process_voice_input() [STT]
        Voice-->>Service: transcribed text
    end

    Service->>Orch: handle_chat(request)

    Note over Orch: 1. Retrieve context
    Orch->>Mem: get_conversation_context()
    Orch->>Mem: get_memories(query)
    Orch->>Mem: get_basic_identity_facts()

    Note over Orch: 2. Safety check
    Orch->>Guard: check_safety(message)
    Guard-->>Orch: GuardrailDecision

    Note over Orch: 3. Detect special topics
    Orch->>Orch: check_financial_thread()
    Orch->>Orch: check_future_planning()

    alt Financial Topic Detected
        Orch->>WS: notify_financial_topic_to_creator()
        Orch-->>Service: acknowledgment response
    else Future Planning Detected
        Orch->>WS: notify_future_request_to_creator()
        Orch-->>Service: acknowledgment response
    else Normal Message
        Note over Orch: 4. Compose response
        Orch->>Orch: get_tone_instructions()
        Orch->>Orch: get_relationship_info()
        Orch->>LLM: chat.completions.create()
        LLM-->>Orch: AI response
    end

    Note over Orch: 5. Background tasks
    Orch->>Listener: process() [log + summarize]
    Orch-->>Service: OrchestratorOutput

    alt Voice Output
        Service->>Voice: generate_voice_response() [TTS]
        Voice-->>Service: voice_url
    end

    Service-->>API: ChatResponse
    API-->>User: JSON response
```

### 2. Creator Flow (Owner â†’ Twin)

The creator (twin owner) chats with their own twin to teach it about themselves.

1. **Input processing** â€” same voice I/O pipeline
2. **Memory retrieval** â€” fetches creator-specific memories
3. **Response composition** â€” uses creator-specific LLM instructions that encourage learning
4. **Background learning** â€” extracts facts from the conversation and stores them in memory via mem0

### 3. Passive Observation Flow

The system passively records messages that the twin's owner has with others in external messaging apps.

1. **Batch ingestion** â€” receives batches of messages via `POST /api/v1/passive`
2. **Voice processing** â€” transcribes any voice messages
3. **Storage** â€” stores in PostgreSQL `passive_observations` table
4. **Last message tracking** â€” tracks the latest synced message ID for incremental sync
5. **Background summarization** â€” periodically summarizes accumulated passive messages

---

## Key Components

### OrchestratorAgent (The Brain)

The central orchestrator handles all chat logic. It:

- **Retrieves context**: conversation summary, memories, identity facts, chat history
- **Manages stranger detection**: identifies if a user is unknown and handles introductions
- **Detects wrong names**: if someone addresses the twin by the wrong name
- **Detects financial topics**: routes investment, crypto, and money questions to the real owner
- **Detects future planning**: routes scheduling/meeting requests to the real owner
- **Delivers creator responses**: when the creator responds to financial/planning requests, delivers them in the next chat
- **Applies tone matching**: uses detected tone profiles and relationship context
- **Composes responses**: uses OpenAI LLM with rich system prompts including personality, facts, tone, and time-awareness

### Memory System (mem0 + Qdrant)

- **Semantic memory** via mem0 with Qdrant vector store
- **Memory types**: user messages, summaries, creator thoughts, basic identity facts
- **Custom extraction prompts** for Persian/English bilingual content
- **Profile snapshots** for quick identity retrieval
- **BAAI/bge-m3 embeddings** (runs locally or falls back to online)

### Guardrails

- **Whitelist patterns** â€” greetings, short responses bypass LLM check
- **Blocklist patterns** â€” jailbreak attempts, data extraction blocked immediately
- **Self-query detection** â€” when users ask about themselves, routes to profile-aware response
- **LLM safety check** â€” for ambiguous messages, uses LLM to classify relevance

### Tone Detection

- **Analyzes conversations** between pairs of users
- **Generates per-user tone profiles**: formality, humor, emoji usage, warmth, emotional dependence
- **Detects relationship class**: spouse, family, boss, subordinate, colleague, friend, stranger
- **Updates dynamically** via scheduled background analysis

### Summarization

- **Per-conversation summaries** using LLM (with support for incremental/rolling summaries)
- **Fact extraction** â€” identifies high/medium/low priority facts (identity, occupation, family, preferences)
- **Passive summarization** â€” processes passively observed conversations in background

### Schedulers (Background Workers)

| Scheduler                           | Purpose                                                  |
|-------------------------------------|----------------------------------------------------------|
| **ToneScheduler**                   | Periodically analyzes conversation pairs for tone/personality |
| **ToneRetryWorker**                 | Retries failed tone analyses                              |
| **FeedbackScheduler**               | Generates relationship classification questions           |
| **RetryWorker**                     | Retries failed summarizations                             |
| **PassiveSummarizationScheduler**   | Summarizes passively observed conversations               |
| **PassiveSummarizationRetryWorker** | Retries failed passive summarizations                     |

### Real-time Notifications (WebSocket)

- Maintains per-user WebSocket connections
- Notifies creators about: new financial topics, new future-planning requests, financial thread messages, delivered responses
- Includes 30-second heartbeat ping

### Voice System

- **STT**: OpenAI Whisper API â€” transcribes user voice messages
- **TTS**: OpenAI TTS API â€” generates voice responses
- **Storage**: Saves voice files to disk, serves via `/voices/` endpoint
- **Bidirectional**: Both input and output can be voice

### Observability Stack

| Component       | Purpose                                           | Port  |
|-----------------|---------------------------------------------------|-------|
| **Phoenix**     | AI/LLM trace visualization (OpenTelemetry)         | 6006  |
| **Prometheus**  | Metrics collection (HTTP, LLM, scheduling)          | 9091  |
| **Grafana**     | Metrics dashboards and alerting âš ï¸ **(WIP â€” not yet complete)** | 3000  |
| **PostgreSQL Exporter** | PostgreSQL metrics for Prometheus           | 9187  |

> âš ï¸ **Note:** Grafana dashboards are still a work in progress. The infrastructure is provisioned and running, but custom dashboards and alerting rules have not been fully configured yet.

---

## Infrastructure (Docker Compose)

The `docker-compose.yaml` brings up:

1. **Qdrant** â€” vector database for semantic memory search
2. **PostgreSQL 16** â€” relational database for chat history, feedback, threads
3. **PostgreSQL Exporter** â€” exposes PG metrics to Prometheus
4. **Phoenix** â€” AI observability with OTLP receiver
5. **Prometheus** â€” metrics scraping and storage
6. **Grafana** â€” dashboards (auto-provisioned datasources & dashboards) âš ï¸ **WIP**
7. **SQLite Helper** â€” ensures permissions on local SQLite data

---

## Configuration

All configuration via environment variables (`.env` file), managed by Pydantic `Settings`:

| Category           | Key Variables                                                          |
|--------------------|------------------------------------------------------------------------|
| **Database**       | `POSTGRES_HOST`, `POSTGRES_PORT`, `POSTGRES_DB`, `POSTGRES_USER`, `POSTGRES_PASSWORD` |
| **Vector DB**      | `QDRANT_URL`                                                           |
| **LLM Models**     | `COMPOSER_MODEL`, `CREATOR_MODEL`, `GUARDRAIL_MODEL`, `SUMMARIZER_MODEL`, `TONE_MODEL`, `FACT_EXTRACTOR_MODEL` |
| **LLM Temps**      | `COMPOSER_TEMPERATURE`, `CREATOR_TEMPERATURE`, etc.                    |
| **Memory**         | `MEM0_LLM_MODEL`, `MEM0_EMBEDDING_MODEL`                              |
| **Voice**          | `VOICE_ENABLED`, `VOICE_STT_MODEL`, `VOICE_TTS_MODEL`, `VOICE_STORAGE_PATH` |
| **Scheduling**     | `TONE_SCHEDULER_INTERVAL`, `FEEDBACK_SCHEDULER_INTERVAL`, etc.         |
| **OpenAI**         | `OPENAI_API_KEY`, `OPENAI_BASE_URL`                                    |

---

## Messenger Integration â€” Twin Mode

This application is designed to be integrated into a **messaging platform**. When deployed inside a messenger, the user needs a **Twin Mode** toggle that allows switching between:

- **ğŸŸ¢ Twin Mode ON** â€” The AI Twin automatically responds to incoming messages on behalf of the user. Messages are processed through the chat API, and the twin generates responses using the user's learned personality, tone, and knowledge.
- **ğŸ”´ Twin Mode OFF** â€” Normal messaging mode. The user reads and responds to messages themselves. Messages can still be recorded via the Passive API for learning purposes.

### Tone-Aware Responses

A key feature of this system is **automatic tone detection**. The application continuously analyzes conversations between users (both in Twin Mode ON and OFF) to detect and learn each user's unique communication style â€” including formality level, humor, emoji usage, warmth, and emotional patterns.

When **Twin Mode is ON**, the AI Twin doesn't just respond with generic answers. It **mimics the real user's tone and style** for each specific contact:

- If the user speaks casually with friends (using slang, emojis, humor), the Twin responds the same way
- If the user speaks formally with their boss, the Twin matches that formality
- The tone adapts **per-relationship**: the same Twin responds differently to a spouse vs. a colleague

This is achieved through the **Tone Detection Agent**, which periodically analyzes passive observations and builds per-pair tone profiles. These profiles are then injected into the LLM's system prompt when generating responses, ensuring the AI Twin's replies are indistinguishable from the real user's writing style.

### How Twin Mode Works

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Messenger App                         â”‚
â”‚                                                          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”‚
â”‚   â”‚  Twin Mode Toggle:  [ON ğŸ¤–] / [OFF ğŸ‘¤]      â”‚      â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚
â”‚                                                          â”‚
â”‚   When ON:                                               â”‚
â”‚     Incoming msg â†’ POST /api/v1/chat â†’ AI response      â”‚
â”‚     User sees AI responses in chat                       â”‚
â”‚                                                          â”‚
â”‚   When OFF:                                              â”‚
â”‚     Incoming msg â†’ shown to user normally                â”‚
â”‚     User's replies â†’ POST /api/v1/passive (learning)    â”‚
â”‚     Twin learns from user's real conversations           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Recommended Open-Source Messengers

To implement Twin Mode, you need an open-source messenger whose codebase you can modify to add the twin toggle and API integration. Here are the best candidates:

| Messenger                                                        | Platform           | Language         | Why It's a Good Fit                                                    |
|------------------------------------------------------------------|--------------------|--------------------|------------------------------------------------------------------------|
| **[Rocket.Chat](https://github.com/RocketChat/Rocket.Chat)**    | Web, Mobile, Desktop | TypeScript/JS    | Full-featured, extensive bot/integration API, webhook support, plugin system |
| **[Mattermost](https://github.com/mattermost/mattermost)**      | Web, Mobile, Desktop | Go + React       | Slack-like, strong plugin architecture, bot accounts, webhook integrations |
| **[Element / Matrix](https://github.com/element-hq/element-web)** | Web, Mobile, Desktop | TypeScript/Rust  | Decentralized protocol, bot SDK (matrix-bot-sdk), bridge support       |
| **[Signal](https://github.com/signalapp)**                       | Mobile, Desktop      | Java/Swift/Rust  | End-to-end encrypted, needs signal-cli or libsignal for bot integration |
| **[Telegram (TDLib)](https://github.com/tdlib/td)**              | Mobile, Desktop      | C++/Multi-lang   | Powerful Bot API, userbot support via TDLib, MTProto protocol          |
| **[Zulip](https://github.com/zulip/zulip)**                     | Web, Mobile, Desktop | Python + JS      | Topic-based threads, excellent bot framework, incoming/outgoing webhooks |

### Integration Architecture

```
Messenger App (modified fork)
    â”‚
    â”œâ”€â”€ Twin Mode Toggle (UI switch in settings/chat header)
    â”‚
    â”œâ”€â”€ When Twin Mode = ON:
    â”‚   â”œâ”€â”€ Intercept incoming messages
    â”‚   â”œâ”€â”€ Send to JoowMe API: POST /api/v1/chat
    â”‚   â”œâ”€â”€ Display AI response as if from user
    â”‚   â””â”€â”€ Connect WebSocket for real-time notifications
    â”‚
    â”œâ”€â”€ When Twin Mode = OFF:
    â”‚   â”œâ”€â”€ Normal message flow
    â”‚   â””â”€â”€ Send user's messages to: POST /api/v1/passive (background)
    â”‚
    â””â”€â”€ Creator Dashboard:
        â”œâ”€â”€ Embedded Streamlit UI or custom page
        â”œâ”€â”€ View/respond to financial topics
        â”œâ”€â”€ View/respond to future planning requests
        â””â”€â”€ Answer relationship classification questions
```
